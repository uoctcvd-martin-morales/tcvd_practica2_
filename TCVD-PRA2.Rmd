---
title: "TCVD-PRA2"
subtitle: "Prueba"
author: "Francisco J. Morales & Antonio Martín"
date: "`r Sys.Date()`"
classoption: a4paper
documentclass: book
always_allow_html: true
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    include:
      in_header: 'Header.html'
  pdf_document:
    toc: yes
    toc_depth: '2'
    highlight: default
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(plotly)
library(corrplot)
library(RColorBrewer)
library(corrgram)
```

## Descripción del dataset.

Nos disponemos a estudiar un Dataset cedido por el MLIT (Ministry of Land, Infrastructure, Transport and Tourism) de Japón. Es un dataset que se publicó en Kaggle y contiene Un listado de transacciones de inmuebles desde 2005 a 2019 de las 7 prefecturas de Japón y puedes descargarse en la siguiente url:

https://www.kaggle.com/datasets/nishiodens/japan-real-estate-transaction-prices

Este dataset dispone no sólo del precio de venta del inmuble sino de variables cuantitativas como los metros cuadrados de algunas áreas a destacar, así como el total; como de varialbes cualitativas como el tipo del inmueble, la zona como su actividad (residencial o comercial), forma. Además podemos encontrar algunos flags de interés como si ha sido remodelado recientemente o si es excesivamente grande (>2000m2),

En este ejercicio, nos dispondremos a unificar todos los datos de las 47 prefecturas en el mismo dataset, hacer una limpieza de ellos y entrenar un modelo de regresión para valorar futuros inmuebles (AVM) que estén a la venta y compararlo con la misma oferta para tomar decisiones.

## Integración y selección de los datos de interés a analizar.

Empezamos por cargar el primer fichero que encontramos. Observamos los diferentes tipos de activos que tenemos y descartamos para quedarnos únicamente con las viviendas. Para ello, nos basamos en los campos Use y Purpose. Nuestra filosofía que si alguno de los usos que se le da al inmueble es House, lo consideramos vivienda. Si el campo está vacío, tomamos el valor de Purpose.

```{r, warning=FALSE}
df_japan <- read.csv("data/japan_housing_data/trade_prices/01.csv")
df_japan_0 <- read.csv("data/japan_housing_data/trade_prices/01.csv")

table(df_japan$Type)

# df_japan <- df_japan[df_japan[,'Type'] != 'Agricultural Land' & df_japan[,'Type'] != 'Forest Land',]

head(table(df_japan$Use))

head(table(df_japan$Purpose))

df_japan[df_japan$Use=='','Use'] <- df_japan[df_japan$Use=='','Purpose']
df_japan <- subset(df_japan, grepl("House", df_japan$Use))
```

Como desconocemos si cada vivienda tiene un identificador como la referencia catastral aquí en España, o algún indicador en el que se vea si se ha hecho una división horizontal. Es más, como ni siquiera disponemos de la dirección, no es imposible determinar al 100% si dos ventas se refieren al mismo inmueble. El hecho aquí, es que hablamos de ventas y suponemos que una venta está duplicada si todos los campos son iguales. Es decir, si se vende el mismo inmueble, el mismo año, en el mismo quarter, pero con diferente precio, lo vamos a considerar como una venta diferente. Si mas adelante vemos que esto empeora el modelo, rectificaremos.

```{r, warning=FALSE}
duplicados <- nrow(df_japan[duplicated(df_japan), ])
df_japan <- df_japan[!duplicated(df_japan), ]

```


Una vez hemos cargado el primer fichero, hacemos un bucle para cargar el resto. Para optimizar recursos, iremos filtrando los tipos y revisando los duplicados en cada fichero.

```{r, warning=FALSE}
resources_root <-"data/japan_housing_data/trade_prices/"

for(i in seq(from=2, to=47)){
  index_file <- paste('0',toString(i),sep = "",collapse = NULL)
  file <- paste(resources_root,substr(index_file, nchar(index_file)-1, nchar(index_file)),'.csv',sep = "",collapse = NULL)
  df <- read.csv(file)
  
  df[df_japan$Use=='','Use'] <- df[df$Use=='','Purpose']
  df <- subset(df, grepl("House", df$Use))
  
  duplicados <- nrow(df[duplicated(df), ]) + duplicados
  df <- df[!duplicated(df), ]

  
  df_japan <- union(df_japan,df)
}
```

Ahora, seleccionaremos los campos que a priori creemos que nos servirán para el modelo y excluiremos las redundantes.

```{r, warning=FALSE}
columns <- c("No","Type","Region","MunicipalityCode","Prefecture","Municipality","DistrictName","NearestStation",
             "TimeToNearestStation","MaxTimeToNearestStation","TradePrice","FloorPlan","Area","UnitPrice",
             "LandShape","Frontage","BuildingYear","Structure","CityPlanning","Year","Quarter","Renovation")

df_japan <- df_japan[,columns]
```

## Limpieza de los datos.

Para empezar le daremos una vista general a set de datos.

```{r, warning=FALSE}
str(df_japan)

summary(df_japan)

duplicados
```
Podemos ver que, según nuestra definición, no tenemos ventas duplicadas. 

Tomamos las siguientes decisiones.

* Eliminamos el ID que realmente no nos dice nada.
* Nos quedamos con el máximo tiempo hasta la estación más próxima. Somos pesimistas en este aspecto.
* Eliminamos el precio en moneda extranjera.
* Calculamos nosotros el precio por metro cuadrado dividiendo el precio de la venta entre el área. Asumimos que el campo AREA, incluye el resto de campos referidos a superficies.



```{r, warning=FALSE}
df_japan$Region[df_japan$Region == ''] <- "Other"

table(df_japan$Type,df_japan$Region)

table(df_japan$Year)

df_japan$FloorPlan[df_japan$FloorPlan == ''] <- "-"

df_japan$DistrictName[df_japan$DistrictName == '(No Address)'] <- "-"
df_japan$DistrictName[df_japan$DistrictName == ''] <- "-"
df_japan$NearestStation[df_japan$NearestStation == ''] <- "-"
df_japan$LandShape[df_japan$LandShape == ''] <- "-"
df_japan$Renovation[df_japan$Renovation == ''] <- "-"
df_japan$Structure[df_japan$Structure == ''] <- "-"
df_japan[is.na(df_japan$Frontage),'Frontage'] <- 0

df_japan <- df_japan[!is.na(df_japan$TradePrice),]
df_japan <- df_japan[!is.na(df_japan$Area),]

df_japan$UnitPrice<- df_japan$TradePrice/df_japan$Area
```

#Outliers

Quitamos Outliers para limpiar los datos.

```{r, warning=FALSE}
rating_plot <- ggplot(df_japan, aes(y=TradePrice)) + geom_boxplot()

ggplotly(rating_plot)

out_ <- boxplot.stats(df_japan$TradePrice)$out

idx_out_ <- which(df_japan$TradePrice %in% out_)

df_japan<- df_japan[-idx_out_,]

```

## Análisis de los datos.

### Selección de los grupos de datos que se quieren analizar/comparar.

### Comprobación de la normalidad y homogeneidad de la varianza.

### Aplicación de pruebas estadísticas para comparar los grupos de datos.

## Representación de los resultados a partir de tablas y gráficas.

## Resolución del problema.
